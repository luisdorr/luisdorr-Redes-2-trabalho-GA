# OSPF-Gaming

OSPF-Gaming is a QoS-aware link-state routing daemon for educational labs. Each router floods latency, jitter, loss, and static bandwidth observations, and the control plane maps the link-state database into Layer-3 next-hop decisions with Dijkstra.

## Quick Start
- Install Docker, Docker Compose, and Python 3.11 with `pip install pandas matplotlib PyYAML` on the host.
- Generate the lab assets:
  - `python generate_frr_configs.py`
  - `python generate_compose.py`
- Run the automated comparison (`analysis.py` spins the topologies, measures pings r1->r5, degrades r3, and stores CSV/plots):
  - `python analysis.py`

## What the Experiment Does
- Spins up the eight OSPF-Gaming routers and the FRR/OSPF baseline using the compose files in the project root.
- Records baseline ICMP latency, jitter, and loss between r1 and r5.
- Injects delay and loss on `r3:eth0` with `tc netem` to penalise the direct path.
- Tracks the time until r1 installs a new next-hop for 10.0.35.3, capturing convergence for both protocols.
- Repeats the ping measurements after convergence and stores raw outputs under `results/raw/<protocol>/`.

## Outputs
- Tables under `results/tables/` (`latency_jitter_loss.csv`, `convergence.csv`).
- Figures under `results/figures/` (`latency_jitter.png`, `convergence.png`) when `matplotlib` is available.
- Generated FRR configs live in `configs/`, while Docker manifests are `docker-compose.yml` (OSPF-Gaming) and `docker-compose.frr.yml` (FRR baseline).

## Manual Lab Control
- Launch OSPF-Gaming only: `docker compose -f docker-compose.yml up -d`
- Launch FRR baseline: `docker compose -f docker-compose.frr.yml up -d`
- Tear down a topology: `docker compose -f <file> down -v`

### How to Degrade a Route Manually
To simulate impairments on the link of `r3` (for testing failover and QoS awareness):

- Apply degradation (adds 20% loss, 100ms delay, Â±20ms jitter)  
```
docker exec r3 tc qdisc add dev eth0 root netem loss 20% delay 100ms 20ms
```

- Remove degradation and restore normal operation  
```
docker exec r3 tc qdisc del dev eth0 root
```

ðŸ’¡ To check which interface to impair, run:  
```
docker exec r3 ip route get 10.0.35.3
```
This shows which interface (`eth0`, `eth1`, etc.) is currently used as next hop toward the destination.

## Code Map
- `algorithm.py` â€” shortest-path computation returning next hops and costs.
- `metrics.py` â€” active ICMP probing plus QoS cost normalisation.
- `ospf_gaming_daemon.py` â€” Hello/LSA flooding, QoS weighting, and kernel FIB sync.
- `route_manager.py` â€” thin wrapper around `ip route` for FIB updates.
- `analysis.py` â€” automation for the r1->r5 convergence experiment.
- `generate_compose.py` / `generate_frr_configs.py` â€” regenerate topology manifests from `config/*.json`.

## Reporting
- After running `analysis.py`, reference the CSV files and plots in your presentation or course report.
- For live inspection inside the lab, `docker exec r1 ip route get 10.0.35.3` shows the current next hop selected by the QoS-aware control plane.
